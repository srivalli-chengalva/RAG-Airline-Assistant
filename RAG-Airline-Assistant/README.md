# âœˆï¸ Airline Dispute RAG Assistant

A fully local, $0-cost RAG (Retrieval-Augmented Generation) system for resolving airline disputes â€” refunds, disruptions, and baggage issues â€” grounded in real airline policies and DOT regulations.

---

## ğŸ§  What It Does

Users describe their airline dispute in plain language. The system:
1. **Detects** the issue type (refund/disruption or baggage)
2. **Extracts slots** (airline name, cancellation type, baggage status, etc.)
3. **Asks clarifying questions** if required information is missing
4. **Retrieves** the most relevant policy chunks from a local vector database
5. **Reranks** results using a cross-encoder for production-grade precision
6. **Returns** a grounded answer with citations and confidence scores

No OpenAI. No API costs. Runs entirely on your machine.

---

## ğŸ—ï¸ Tech Stack

| Layer | Technology | Purpose |
|---|---|---|
| LLM (Day 2) | Ollama â€” `llama3.1:8b` | Slot extraction, answer generation |
| Embeddings | `intfloat/e5-base-v2` | Semantic chunk encoding |
| Vector DB | ChromaDB (local) | Persistent similarity search |
| Reranker | `BAAI/bge-reranker-base` | Cross-encoder precision boost |
| Backend | FastAPI | REST API â€” `/chat`, `/ingest` |
| Frontend | Streamlit | Chat UI with evidence panel |
| Decision Logic | YAML Playbooks (Day 3) | Eligibility rules engine |

---

## ğŸ“ Project Structure

```
airline-rag-assistant/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py          # Package marker
â”‚   â”œâ”€â”€ config.py            # All settings (models, paths, thresholds)
â”‚   â”œâ”€â”€ ingestion.py         # Policy chunking + embedding (module version)
â”‚   â”œâ”€â”€ retrieval.py         # Two-stage retrieval: dense search + reranker
â”‚   â”œâ”€â”€ slots.py             # Slot extraction + missing-info detector
â”‚   â””â”€â”€ main.py              # FastAPI app â€” /health, /ingest, /chat
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ policies/
â”‚       â”œâ”€â”€ _meta/
â”‚       â”‚   â””â”€â”€ authority_cross_reference_2026-02.txt   # Internal rules (DO_NOT_CITE)
â”‚       â”œâ”€â”€ American_Airlines/
â”‚       â”‚   â”œâ”€â”€ american_checked_baggage_policy_2026-02.txt
â”‚       â”‚   â”œâ”€â”€ american_optional_service_fees_2026-02.txt
â”‚       â”‚   â””â”€â”€ american_refund_policy_2026-02.txt
â”‚       â”œâ”€â”€ Delta_Air_Lines/
â”‚       â”‚   â”œâ”€â”€ delta_baggage_2026-02.txt
â”‚       â”‚   â””â”€â”€ delta_refund_policy_2026-02.txt
â”‚       â”œâ”€â”€ United_Airlines/
â”‚       â”‚   â”œâ”€â”€ united_baggage_policy_2026-02.txt
â”‚       â”‚   â””â”€â”€ united_refund_policy_2026-02.txt
â”‚       â””â”€â”€ DOT/
â”‚           â”œâ”€â”€ dot_baggage_2026-02.txt
â”‚           â””â”€â”€ dot_refunds_2026-02.txt
â”‚
â”œâ”€â”€ playbooks/               # YAML decision rules (Day 3)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest_docs.py       # CLI: run once to populate vector store
â”‚   â””â”€â”€ check_store.py       # CLI: verify vector store contents
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py               # Streamlit chat interface
â”‚
â”œâ”€â”€ vector_store/            # Auto-created by ChromaDB â€” DO NOT commit to Git
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš¡ Quickstart

### 1. Prerequisites

- Python 3.10+
- [Ollama](https://ollama.com/download) installed and running (for Day 2 LLM features)

```bash
ollama pull llama3.1:8b
```

### 2. Clone and set up environment

```bash
git clone <your-repo-url>
cd airline-rag-assistant

# Create virtual environment
python -m venv .venv

# Activate â€” Mac/Linux
source .venv/bin/activate

# Activate â€” Windows PowerShell
.\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt
```

### 3. Ingest policy documents

Run from the project root:

```bash
python scripts/ingest_docs.py
```

Expected output:
```
âœ… Ingestion complete
   Files ingested:  10
   Chunks ingested: 118
   Vector store:    vector_store/
```

### 4. Verify vector store (optional)

```bash
python scripts/check_store.py
```

### 5. Start the backend API

```bash
uvicorn backend.main:app --reload
```

API docs available at: http://127.0.0.1:8000/docs

### 6. Start the Streamlit UI

Open a second terminal (with `.venv` activated):

```bash
streamlit run ui/app.py
```

UI opens at: http://localhost:8501

---

## ğŸ”„ RAG Pipeline (How It Works)

```
User message
     â”‚
     â–¼
detect_case()          â†’ "refund" or "baggage"
     â”‚
     â–¼
extract_slots()        â†’ airline, cancellation type, baggage status, etc.
     â”‚
     â–¼
missing_slots()?       â†’ ask clarifying question if required info missing
     â”‚
     â–¼
build_retrieval_query() â†’ enrich query with slot context
     â”‚
     â–¼
retriever.retrieve()   â†’ Stage 1: dense vector search (top 12 candidates)
     â”‚
     â–¼
retriever.rerank()     â†’ Stage 2: cross-encoder reranking (top 5)
     â”‚
     â–¼
evidence_gate()        â†’ check confidence threshold
     â”‚
     â–¼
build_answer()         â†’ grounded response with citations
```

---

## ğŸ—„ï¸ Policy Document Format

Each policy file uses a structured format for reliable ingestion:

```
SOURCE: American Airlines
URL: https://www.aa.com/...
CAPTURED_ON: 2026-02-12
AUTHORITY: AIRLINE          â† or REGULATOR for DOT files
DOMAIN: BAGGAGE             â† or REFUND, BAGGAGE_FEES, etc.

SECTION: Delayed Baggage Procedures
[policy content here]

SECTION: Lost Baggage
[policy content here]
```

Files in `_meta/` with `DO_NOT_CITE: TRUE` are used for internal retrieval logic but are never shown to users.

---

## ğŸ›ï¸ Configuration

All tunable settings live in `backend/config.py`:

| Setting | Default | Description |
|---|---|---|
| `embed_model` | `intfloat/e5-base-v2` | Embedding model |
| `reranker_model` | `BAAI/bge-reranker-base` | Cross-encoder reranker |
| `retrieval_top_k` | `12` | Candidates fetched from vector DB |
| `rerank_top_n` | `5` | Kept after reranking |
| `rerank_threshold_none` | `0.30` | Below â†’ ask for clarification |
| `rerank_threshold_low` | `0.50` | Below â†’ low confidence warning |
| `ollama_model` | `llama3.1:8b` | LLM for generation (Day 2) |

---

## ğŸ§ª Example Queries

| Query | Expected Behavior |
|---|---|
| `"My Delta flight was canceled, can I get a refund?"` | Returns Delta + DOT refund policy with high confidence |
| `"American Airlines lost my bag"` | Returns AA + DOT lost baggage policy |
| `"I have a baggage issue"` | Asks: *"Is your baggage lost, delayed, or damaged?"* |
| `"United delayed my bag by 2 days, can I be reimbursed?"` | Returns United + DOT delayed baggage reimbursement policy |
| `"What does DOT say about significant schedule changes?"` | Returns DOT refund regulation sections |

---

## ğŸ—ºï¸ Roadmap

- [x] **Day 1** â€” Ingestion, retrieval, reranker, slot extraction, FastAPI, Streamlit UI
- [ ] **Day 2** â€” Ollama LLM generation (grounded answers, not just excerpts)
- [ ] **Day 3** â€” YAML playbook decision engine (eligibility rules)
- [ ] **Day 4** â€” Evaluation scripts (Recall@k, retrieval accuracy)
- [ ] **Day 5** â€” Conversation memory + multi-turn slot tracking

---

## âš ï¸ Important Notes

- `vector_store/` is excluded from Git (see `.gitignore`). Run `ingest_docs.py` after cloning.
- Policy files are snapshots captured in February 2026. Always verify current policies directly with airlines or DOT.
- This system is for **informational purposes only** and does not constitute legal advice.

---

## ğŸ“„ License

MIT License â€” see `LICENSE` for details.